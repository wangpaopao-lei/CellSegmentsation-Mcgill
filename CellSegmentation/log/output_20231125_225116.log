第一个脚本已完成运行
2023-11-25 22:52:02.853211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-25 22:52:02.887686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-25 22:52:02.887885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-25 22:52:02.888358: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-25 22:52:02.892043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-25 22:52:02.892241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-25 22:52:02.892397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-25 22:52:03.282284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-25 22:52:03.282500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-25 22:52:03.282662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-25 22:52:03.282812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18994 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9
2023-11-25 22:52:03.750402: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 10059200000 exceeds 10% of free system memory.
2023-11-25 22:52:16.455787: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 10059200000 exceeds 10% of free system memory.
results folder exists.
Epoch 1/30
2023-11-25 22:52:22.517085: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2023-11-25 22:52:47.977604: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2515200000 exceeds 10% of free system memory.
2023-11-25 22:52:49.381742: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2515200000 exceeds 10% of free system memory.
2515/2515 - 33s - loss: 0.0236 - accuracy: 0.9967 - val_loss: 0.0050 - val_accuracy: 0.9990 - 33s/epoch - 13ms/step
Epoch 2/30
2515/2515 - 28s - loss: 0.0180 - accuracy: 0.9967 - val_loss: 0.0083 - val_accuracy: 0.9975 - 28s/epoch - 11ms/step
Epoch 3/30
2515/2515 - 28s - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0123 - val_accuracy: 0.9973 - 28s/epoch - 11ms/step
Epoch 4/30
2515/2515 - 28s - loss: 0.0138 - accuracy: 0.9944 - val_loss: 0.0021 - val_accuracy: 0.9994 - 28s/epoch - 11ms/step
Epoch 5/30
2515/2515 - 27s - loss: 0.0043 - accuracy: 0.9992 - val_loss: 8.9957e-04 - val_accuracy: 0.9997 - 27s/epoch - 11ms/step
Epoch 6/30
2515/2515 - 28s - loss: 0.0049 - accuracy: 0.9990 - val_loss: 0.0108 - val_accuracy: 0.9987 - 28s/epoch - 11ms/step
Epoch 7/30
2515/2515 - 28s - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0180 - val_accuracy: 0.9971 - 28s/epoch - 11ms/step
Epoch 8/30
2515/2515 - 28s - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0167 - val_accuracy: 0.9983 - 28s/epoch - 11ms/step
Epoch 9/30
2515/2515 - 28s - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0129 - val_accuracy: 0.9978 - 28s/epoch - 11ms/step
Epoch 10/30
2515/2515 - 28s - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0026 - val_accuracy: 0.9992 - 28s/epoch - 11ms/step
Epoch 11/30
2515/2515 - 27s - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0018 - val_accuracy: 0.9998 - 27s/epoch - 11ms/step
Epoch 12/30
2515/2515 - 28s - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0300 - val_accuracy: 0.9978 - 28s/epoch - 11ms/step
Epoch 13/30
2515/2515 - 28s - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0014 - val_accuracy: 0.9997 - 28s/epoch - 11ms/step
Epoch 14/30
2515/2515 - 28s - loss: 1.3620e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9995 - 28s/epoch - 11ms/step
Epoch 15/30
2515/2515 - 28s - loss: 0.0079 - accuracy: 0.9990 - val_loss: 0.0133 - val_accuracy: 0.9979 - 28s/epoch - 11ms/step
Epoch 16/30
2515/2515 - 28s - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0040 - val_accuracy: 0.9992 - 28s/epoch - 11ms/step
Epoch 17/30
2515/2515 - 28s - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0077 - val_accuracy: 0.9987 - 28s/epoch - 11ms/step
Epoch 18/30
2515/2515 - 28s - loss: 7.4185e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9989 - 28s/epoch - 11ms/step
Epoch 19/30
2515/2515 - 28s - loss: 0.0050 - accuracy: 0.9994 - val_loss: 0.0131 - val_accuracy: 0.9976 - 28s/epoch - 11ms/step
Epoch 20/30
2515/2515 - 28s - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0015 - val_accuracy: 0.9994 - 28s/epoch - 11ms/step
Epoch 21/30
2515/2515 - 28s - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0082 - val_accuracy: 0.9983 - 28s/epoch - 11ms/step
Epoch 22/30
2515/2515 - 28s - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0128 - val_accuracy: 0.9986 - 28s/epoch - 11ms/step
Epoch 23/30
2515/2515 - 28s - loss: 1.3672e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9995 - 28s/epoch - 11ms/step
Epoch 24/30
2515/2515 - 28s - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0094 - val_accuracy: 0.9984 - 28s/epoch - 11ms/step
Epoch 25/30
2515/2515 - 28s - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0126 - val_accuracy: 0.9987 - 28s/epoch - 11ms/step
Epoch 26/30
2515/2515 - 27s - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0116 - val_accuracy: 0.9989 - 27s/epoch - 11ms/step
Epoch 27/30
2515/2515 - 28s - loss: 9.3872e-04 - accuracy: 0.9997 - val_loss: 0.0150 - val_accuracy: 0.9983 - 28s/epoch - 11ms/step
Epoch 28/30
2515/2515 - 27s - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0120 - val_accuracy: 0.9987 - 27s/epoch - 11ms/step
Epoch 29/30
2515/2515 - 28s - loss: 0.0075 - accuracy: 0.9990 - val_loss: 0.0156 - val_accuracy: 0.9973 - 28s/epoch - 11ms/step
Epoch 30/30
2515/2515 - 28s - loss: 1.7214e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9989 - 28s/epoch - 11ms/step
Inference on all the spots...
144.0 in total
Batch 0 processing...
2023-11-25 23:20:22.280644: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4000000000 exceeds 10% of free system memory.
Batch 0 completed. Time taken: 00:14:17
Batch 1 processing...
Batch 1 completed. Time taken: 00:06:21
Batch 2 processing...
Batch 2 completed. Time taken: 00:06:14
Batch 3 processing...
Batch 3 completed. Time taken: 00:05:47
Batch 4 processing...
Batch 4 completed. Time taken: 00:05:20
Batch 5 processing...
Batch 5 completed. Time taken: 00:05:08
Batch 6 processing...
Batch 6 completed. Time taken: 00:05:16
Batch 7 processing...
Batch 7 completed. Time taken: 00:04:58
Batch 8 processing...
Batch 8 completed. Time taken: 00:04:53
Batch 9 processing...
Batch 9 completed. Time taken: 00:04:51
Batch 10 processing...
Batch 10 completed. Time taken: 00:04:45
Batch 11 processing...
Batch 11 completed. Time taken: 00:04:46
Batch 12 processing...
Batch 12 completed. Time taken: 00:04:40
Batch 13 processing...
Batch 13 completed. Time taken: 00:04:41
Batch 14 processing...
Batch 14 completed. Time taken: 00:04:38
Batch 15 processing...
Batch 15 completed. Time taken: 00:04:36
Batch 16 processing...
Batch 16 completed. Time taken: 00:04:37
Batch 17 processing...
Batch 17 completed. Time taken: 00:04:37
Batch 18 processing...
Batch 18 completed. Time taken: 00:04:37
Batch 19 processing...
Batch 19 completed. Time taken: 00:04:36
Batch 20 processing...
Batch 20 completed. Time taken: 00:04:35
Batch 21 processing...
Batch 21 completed. Time taken: 00:04:35
Batch 22 processing...
Batch 22 completed. Time taken: 00:04:35
Batch 23 processing...
Batch 23 completed. Time taken: 00:04:35
Batch 24 processing...
Batch 24 completed. Time taken: 00:04:35
Batch 25 processing...
Batch 25 completed. Time taken: 00:04:35
Batch 26 processing...
Batch 26 completed. Time taken: 00:04:34
Batch 27 processing...
Batch 27 completed. Time taken: 00:04:34
Batch 28 processing...
Batch 28 completed. Time taken: 00:04:35
Batch 29 processing...
Batch 29 completed. Time taken: 00:04:35
Batch 30 processing...
Batch 30 completed. Time taken: 00:04:36
Batch 31 processing...
Batch 31 completed. Time taken: 00:04:36
Batch 32 processing...
Batch 32 completed. Time taken: 00:04:34
Batch 33 processing...
Batch 33 completed. Time taken: 00:04:35
Batch 34 processing...
Batch 34 completed. Time taken: 00:04:35
Batch 35 processing...
Batch 35 completed. Time taken: 00:04:34
Batch 36 processing...
Batch 36 completed. Time taken: 00:04:35
Batch 37 processing...
Batch 37 completed. Time taken: 00:04:34
Batch 38 processing...
Batch 38 completed. Time taken: 00:04:34
Batch 39 processing...
Batch 39 completed. Time taken: 00:04:34
Batch 40 processing...
Batch 40 completed. Time taken: 00:04:34
Batch 41 processing...
Batch 41 completed. Time taken: 00:04:35
Batch 42 processing...
Batch 42 completed. Time taken: 00:04:34
Batch 43 processing...
Batch 43 completed. Time taken: 00:04:34
Batch 44 processing...
Batch 44 completed. Time taken: 00:04:35
Batch 45 processing...
Batch 45 completed. Time taken: 00:04:35
Batch 46 processing...
Batch 46 completed. Time taken: 00:04:34
Batch 47 processing...
Batch 47 completed. Time taken: 00:04:35
Batch 48 processing...
Batch 48 completed. Time taken: 00:04:34
Batch 49 processing...
Batch 49 completed. Time taken: 00:04:34
Batch 50 processing...
Batch 50 completed. Time taken: 00:04:34
Batch 51 processing...
Batch 51 completed. Time taken: 00:04:35
Batch 52 processing...
Batch 52 completed. Time taken: 00:04:35
Batch 53 processing...
Batch 53 completed. Time taken: 00:04:35
Batch 54 processing...
Batch 54 completed. Time taken: 00:04:34
Batch 55 processing...
Batch 55 completed. Time taken: 00:04:35
Batch 56 processing...
Batch 56 completed. Time taken: 00:04:35
Batch 57 processing...
Batch 57 completed. Time taken: 00:04:34
Batch 58 processing...
Batch 58 completed. Time taken: 00:04:34
Batch 59 processing...
Batch 59 completed. Time taken: 00:04:34
Batch 60 processing...
Batch 60 completed. Time taken: 00:04:35
Batch 61 processing...
Batch 61 completed. Time taken: 00:04:35
Batch 62 processing...
Batch 62 completed. Time taken: 00:04:34
Batch 63 processing...
Batch 63 completed. Time taken: 00:04:35
Batch 64 processing...
Batch 64 completed. Time taken: 00:04:35
Batch 65 processing...
Batch 65 completed. Time taken: 00:04:34
Batch 66 processing...
Batch 66 completed. Time taken: 00:04:34
Batch 67 processing...
Batch 67 completed. Time taken: 00:04:34
Batch 68 processing...
Batch 68 completed. Time taken: 00:04:33
Batch 69 processing...
Batch 69 completed. Time taken: 00:04:33
Batch 70 processing...
Batch 70 completed. Time taken: 00:04:34
Batch 71 processing...
Batch 71 completed. Time taken: 00:04:35
Batch 72 processing...
Batch 72 completed. Time taken: 00:04:34
Batch 73 processing...
Batch 73 completed. Time taken: 00:04:34
Batch 74 processing...
Batch 74 completed. Time taken: 00:04:34
Batch 75 processing...
Batch 75 completed. Time taken: 00:04:35
Batch 76 processing...
Batch 76 completed. Time taken: 00:04:33
Batch 77 processing...
Batch 77 completed. Time taken: 00:04:34
Batch 78 processing...
Batch 78 completed. Time taken: 00:04:35
Batch 79 processing...
Batch 79 completed. Time taken: 00:04:35
Batch 80 processing...
Batch 80 completed. Time taken: 00:04:36
Batch 81 processing...
Batch 81 completed. Time taken: 00:04:36
Batch 82 processing...
Batch 82 completed. Time taken: 00:04:33
Batch 83 processing...
Batch 83 completed. Time taken: 00:04:34
Batch 84 processing...
Batch 84 completed. Time taken: 00:04:35
Batch 85 processing...
Batch 85 completed. Time taken: 00:04:34
Batch 86 processing...
Batch 86 completed. Time taken: 00:04:35
Batch 87 processing...
Batch 87 completed. Time taken: 00:04:35
Batch 88 processing...
Batch 88 completed. Time taken: 00:04:38
Batch 89 processing...
Batch 89 completed. Time taken: 00:04:34
Batch 90 processing...
Batch 90 completed. Time taken: 00:04:35
Batch 91 processing...
Batch 91 completed. Time taken: 00:04:35
Batch 92 processing...
Batch 92 completed. Time taken: 00:04:34
Batch 93 processing...
Batch 93 completed. Time taken: 00:04:34
Batch 94 processing...
Batch 94 completed. Time taken: 00:04:35
Batch 95 processing...
Batch 95 completed. Time taken: 00:04:34
Batch 96 processing...
Batch 96 completed. Time taken: 00:04:34
Batch 97 processing...
Batch 97 completed. Time taken: 00:04:34
Batch 98 processing...
Batch 98 completed. Time taken: 00:04:35
Batch 99 processing...
Batch 99 completed. Time taken: 00:04:33
Batch 100 processing...
Batch 100 completed. Time taken: 00:04:35
Batch 101 processing...
Batch 101 completed. Time taken: 00:04:34
Batch 102 processing...
Batch 102 completed. Time taken: 00:04:34
Batch 103 processing...
Batch 103 completed. Time taken: 00:04:35
Batch 104 processing...
Batch 104 completed. Time taken: 00:04:35
Batch 105 processing...
Batch 105 completed. Time taken: 00:04:35
Batch 106 processing...
Batch 106 completed. Time taken: 00:04:34
Batch 107 processing...
Batch 107 completed. Time taken: 00:04:34
Batch 108 processing...
Batch 108 completed. Time taken: 00:04:33
Batch 109 processing...
Batch 109 completed. Time taken: 00:04:34
Batch 110 processing...
Batch 110 completed. Time taken: 00:04:34
Batch 111 processing...
Batch 111 completed. Time taken: 00:04:34
Batch 112 processing...
Batch 112 completed. Time taken: 00:04:35
Batch 113 processing...
Batch 113 completed. Time taken: 00:04:35
Batch 114 processing...
Batch 114 completed. Time taken: 00:04:35
Batch 115 processing...
Batch 115 completed. Time taken: 00:04:34
Batch 116 processing...
Batch 116 completed. Time taken: 00:04:35
Batch 117 processing...
Batch 117 completed. Time taken: 00:04:35
Batch 118 processing...
Batch 118 completed. Time taken: 00:04:35
Batch 119 processing...
Batch 119 completed. Time taken: 00:04:35
Batch 120 processing...
Batch 120 completed. Time taken: 00:04:34
Batch 121 processing...
Batch 121 completed. Time taken: 00:04:35
Batch 122 processing...
Batch 122 completed. Time taken: 00:04:34
Batch 123 processing...
Batch 123 completed. Time taken: 00:04:33
Batch 124 processing...
Batch 124 completed. Time taken: 00:04:34
Batch 125 processing...
Batch 125 completed. Time taken: 00:04:34
Batch 126 processing...
Batch 126 completed. Time taken: 00:04:35
Batch 127 processing...
Batch 127 completed. Time taken: 00:04:34
Batch 128 processing...
Batch 128 completed. Time taken: 00:04:34
Batch 129 processing...
Batch 129 completed. Time taken: 00:04:34
Batch 130 processing...
Batch 130 completed. Time taken: 00:04:34
Batch 131 processing...
Batch 131 completed. Time taken: 00:04:35
Batch 132 processing...
Batch 132 completed. Time taken: 00:04:36
Batch 133 processing...
Batch 133 completed. Time taken: 00:04:34
Batch 134 processing...
Batch 134 completed. Time taken: 00:04:43
Batch 135 processing...
Batch 135 completed. Time taken: 00:04:34
Batch 136 processing...
Batch 136 completed. Time taken: 00:04:35
Batch 137 processing...
Batch 137 completed. Time taken: 00:04:34
Batch 138 processing...
Batch 138 completed. Time taken: 00:04:35
Batch 139 processing...
Batch 139 completed. Time taken: 00:04:34
Batch 140 processing...
Batch 140 completed. Time taken: 00:04:35
Batch 141 processing...
Batch 141 completed. Time taken: 00:04:34
Batch 142 processing...
Batch 142 completed. Time taken: 00:04:39
Batch 143 processing...
Batch 143 completed. Time taken: 00:04:35
Traceback (most recent call last):
  File "/mnt/md0/lei/CellSegmentation/transformer1.py", line 334, in <module>
    train()
  File "/mnt/md0/lei/CellSegmentation/transformer1.py", line 325, in train
    run_experiment(learning_rate, weight_decay,transformer_classifier,
  File "/mnt/md0/lei/CellSegmentation/transformer1.py", line 208, in run_experiment
    x_test_pos_ = np.load('dataset/x_test_pos0:0:0:0.npz')
  File "/home/lei/miniconda3/envs/CS/lib/python3.9/site-packages/numpy/lib/npyio.py", line 405, in load
    fid = stack.enter_context(open(os_fspath(file), "rb"))
FileNotFoundError: [Errno 2] No such file or directory: 'dataset/x_test_pos0:0:0:0.npz'
第二个脚本已完成运行
/mnt/md0/lei/CellSegmentation/display.py:6: UserWarning: loadtxt: input contained no data: "results/spot_prediction_0:0:0:0.txt"
  data = np.loadtxt(file_path, delimiter='\t')
Traceback (most recent call last):
  File "/mnt/md0/lei/CellSegmentation/display.py", line 9, in <module>
    x = data[:, 0].astype(int)
IndexError: too many indices for array: array is 1-dimensional, but 2 were indexed
