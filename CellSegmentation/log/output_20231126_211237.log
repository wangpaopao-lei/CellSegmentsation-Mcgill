/home/lei/miniconda3/envs/CS/lib/python3.9/site-packages/spaghetti/network.py:40: FutureWarning:

The next major release of pysal/spaghetti (2.0.0) will drop support for all ``libpysal.cg`` geometries. This change is a first step in refactoring ``spaghetti`` that is expected to result in dramatically reduced runtimes for network instantiation and operations. Users currently requiring network and point pattern input as ``libpysal.cg`` geometries should prepare for this simply by converting to ``shapely`` geometries.

2023-11-26 21:12:41.663957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:12:41.685180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:12:41.685340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:12:41.685679: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-26 21:12:41.688899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:12:41.689053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:12:41.689186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:12:41.689424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:12:41.689565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:12:41.689703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:12:41.689833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20047 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9
/home/lei/miniconda3/envs/CS/lib/python3.9/site-packages/ot/backend.py:2998: UserWarning:

To use TensorflowBackend, you need to activate the tensorflow numpy API. You can activate it by running: 
from tensorflow.python.ops.numpy_ops import np_config
np_config.enable_numpy_behavior()

|-----> Constructing count matrices.
|-----> <insert> __type to uns in AnnData Object.
|-----> <insert> pp to uns in AnnData Object.
|-----> <insert> spatial to uns in AnnData Object.
|-----> <select> stain layer in AnnData Object
|-----> Constructing nuclei mask from staining image.
|-----> <insert> stain_mask to layers in AnnData Object.
|-----> <select> stain_mask layer in AnnData Object
|-----> <select> stain_mask layer in AnnData Object
|-----> Finding peaks with minimum distance 7.
|-----> <insert> stain_distances to layers in AnnData Object.
|-----> <insert> stain_markers to layers in AnnData Object.
|-----> <select> stain layer in AnnData Object
|-----> <select> stain_mask layer in AnnData Object
|-----> <select> stain_markers layer in AnnData Object
|-----> Running Watershed.
|-----> <insert> watershed_labels to layers in AnnData Object.
|-----> <select> stain layer in AnnData Object
|-----> <select> watershed_labels layer in AnnData Object
/home/lei/miniconda3/envs/CS/lib/python3.9/site-packages/anndata/_core/anndata.py:183: ImplicitModificationWarning:

Transforming to str index.

/home/lei/miniconda3/envs/CS/lib/python3.9/site-packages/anndata/_core/anndata.py:183: ImplicitModificationWarning:

Transforming to str index.

159329
finished 8%
finished 17%
finished 25%
finished 33%
finished 42%
finished 50%
finished 58%
finished 67%
finished 75%
finished 83%
finished 92%
finished 100%
finished 8%
finished 17%
finished 25%
finished 33%
finished 42%
finished 50%
finished 58%
finished 67%
finished 75%
finished 83%
finished 92%
finished 100%
16952
320161
(33904, 50, 2)
(33904, 50)
(33904, 50, 2000)
(33904, 2)
(1440000, 50, 2000)
(1440000, 50, 2)
(1440000, 50)
第一个脚本已完成运行
2023-11-26 21:35:09.265700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:35:09.288405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:35:09.288588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:35:09.288867: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-11-26 21:35:09.291952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:35:09.292113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:35:09.292271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:35:09.584922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:35:09.585128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:35:09.585285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-11-26 21:35:09.585426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19544 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9
results folder exists.
Epoch 1/30
2023-11-26 21:35:30.226153: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2515/2515 - 31s - loss: 0.0120 - accuracy: 0.9981 - val_loss: 0.0024 - val_accuracy: 0.9992 - 31s/epoch - 12ms/step
Epoch 2/30
2515/2515 - 27s - loss: 0.0020 - accuracy: 0.9997 - val_loss: 0.0052 - val_accuracy: 0.9984 - 27s/epoch - 11ms/step
Epoch 3/30
2515/2515 - 26s - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.0031 - val_accuracy: 0.9997 - 26s/epoch - 10ms/step
Epoch 4/30
2515/2515 - 24s - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.0024 - val_accuracy: 0.9989 - 24s/epoch - 10ms/step
Epoch 5/30
2515/2515 - 27s - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0239 - val_accuracy: 0.9978 - 27s/epoch - 11ms/step
Epoch 6/30
2515/2515 - 27s - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.0332 - val_accuracy: 0.9935 - 27s/epoch - 11ms/step
Epoch 7/30
2515/2515 - 25s - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0069 - val_accuracy: 0.9983 - 25s/epoch - 10ms/step
Epoch 8/30
2515/2515 - 28s - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0248 - val_accuracy: 0.9967 - 28s/epoch - 11ms/step
Epoch 9/30
2515/2515 - 27s - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0035 - val_accuracy: 0.9990 - 27s/epoch - 11ms/step
Epoch 10/30
2515/2515 - 27s - loss: 0.0034 - accuracy: 0.9996 - val_loss: 0.0088 - val_accuracy: 0.9990 - 27s/epoch - 11ms/step
Epoch 11/30
2515/2515 - 27s - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.0272 - val_accuracy: 0.9967 - 27s/epoch - 11ms/step
Epoch 12/30
2515/2515 - 27s - loss: 4.1622e-04 - accuracy: 0.9999 - val_loss: 0.0239 - val_accuracy: 0.9983 - 27s/epoch - 11ms/step
Epoch 13/30
2515/2515 - 27s - loss: 1.0402e-05 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9994 - 27s/epoch - 11ms/step
Epoch 14/30
2515/2515 - 30s - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0208 - val_accuracy: 0.9970 - 30s/epoch - 12ms/step
Epoch 15/30
2515/2515 - 26s - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9992 - 26s/epoch - 10ms/step
Epoch 16/30
2515/2515 - 27s - loss: 0.0044 - accuracy: 0.9991 - val_loss: 5.3763e-06 - val_accuracy: 1.0000 - 27s/epoch - 11ms/step
Epoch 17/30
2515/2515 - 27s - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0161 - val_accuracy: 0.9981 - 27s/epoch - 11ms/step
Epoch 18/30
2515/2515 - 27s - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.0290 - val_accuracy: 0.9973 - 27s/epoch - 11ms/step
Epoch 19/30
2515/2515 - 27s - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0211 - val_accuracy: 0.9986 - 27s/epoch - 11ms/step
Epoch 20/30
2515/2515 - 27s - loss: 1.0437e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9997 - 27s/epoch - 11ms/step
Epoch 21/30
2515/2515 - 26s - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 0.9994 - 26s/epoch - 10ms/step
Epoch 22/30
2515/2515 - 27s - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 0.9998 - 27s/epoch - 11ms/step
Epoch 23/30
2515/2515 - 27s - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.0056 - val_accuracy: 0.9995 - 27s/epoch - 11ms/step
Epoch 24/30
2515/2515 - 28s - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.0050 - val_accuracy: 0.9990 - 28s/epoch - 11ms/step
Epoch 25/30
2515/2515 - 26s - loss: 1.1545e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9995 - 26s/epoch - 11ms/step
Epoch 26/30
2515/2515 - 27s - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9995 - 27s/epoch - 11ms/step
Epoch 27/30
2515/2515 - 27s - loss: 0.0017 - accuracy: 0.9996 - val_loss: 4.7255e-04 - val_accuracy: 0.9997 - 27s/epoch - 11ms/step
Epoch 28/30
2515/2515 - 27s - loss: 6.4767e-04 - accuracy: 0.9999 - val_loss: 0.0261 - val_accuracy: 0.9973 - 27s/epoch - 11ms/step
Epoch 29/30
2515/2515 - 28s - loss: 0.0037 - accuracy: 0.9994 - val_loss: 9.1748e-04 - val_accuracy: 0.9997 - 28s/epoch - 11ms/step
Epoch 30/30
2515/2515 - 28s - loss: 0.0087 - accuracy: 0.9987 - val_loss: 0.0474 - val_accuracy: 0.9944 - 28s/epoch - 11ms/step
Inference on all the spots...
144.0 in total
Batch 0 processing...
Batch 0 completed. Time taken: 00:08:03
Batch 1 processing...
Batch 1 completed. Time taken: 00:05:38
Batch 2 processing...
Batch 2 completed. Time taken: 00:05:26
Batch 3 processing...
Batch 3 completed. Time taken: 00:05:21
Batch 4 processing...
Batch 4 completed. Time taken: 00:05:11
Batch 5 processing...
Batch 5 completed. Time taken: 00:06:18
Batch 6 processing...
Batch 6 completed. Time taken: 00:05:10
Batch 7 processing...
Batch 7 completed. Time taken: 00:05:11
Batch 8 processing...
Batch 8 completed. Time taken: 00:05:00
Batch 9 processing...
Batch 9 completed. Time taken: 00:04:54
Batch 10 processing...
Batch 10 completed. Time taken: 00:05:41
Batch 11 processing...
Batch 11 completed. Time taken: 00:04:52
Batch 12 processing...
Batch 12 completed. Time taken: 00:05:07
Batch 13 processing...
Batch 13 completed. Time taken: 00:04:54
Batch 14 processing...
Batch 14 completed. Time taken: 00:05:05
Batch 15 processing...
Batch 15 completed. Time taken: 00:05:16
Batch 16 processing...
Batch 16 completed. Time taken: 00:05:02
Batch 17 processing...
Batch 17 completed. Time taken: 00:04:46
Batch 18 processing...
Batch 18 completed. Time taken: 00:04:54
Batch 19 processing...
Batch 19 completed. Time taken: 00:04:49
Batch 20 processing...
Batch 20 completed. Time taken: 00:05:09
Batch 21 processing...
Batch 21 completed. Time taken: 00:05:24
Batch 22 processing...
Batch 22 completed. Time taken: 00:04:52
Batch 23 processing...
Batch 23 completed. Time taken: 00:04:44
Batch 24 processing...
Batch 24 completed. Time taken: 00:04:59
Batch 25 processing...
Batch 25 completed. Time taken: 00:04:48
Batch 26 processing...
Batch 26 completed. Time taken: 00:05:34
Batch 27 processing...
Batch 27 completed. Time taken: 00:04:44
Batch 28 processing...
Batch 28 completed. Time taken: 00:04:53
Batch 29 processing...
Batch 29 completed. Time taken: 00:04:40
Batch 30 processing...
Batch 30 completed. Time taken: 00:04:35
Batch 31 processing...
Batch 31 completed. Time taken: 00:04:50
Batch 32 processing...
Batch 32 completed. Time taken: 00:05:05
Batch 33 processing...
Batch 33 completed. Time taken: 00:04:34
Batch 34 processing...
Batch 34 completed. Time taken: 00:04:35
Batch 35 processing...
Batch 35 completed. Time taken: 00:04:34
Batch 36 processing...
Batch 36 completed. Time taken: 00:04:34
Batch 37 processing...
Batch 37 completed. Time taken: 00:05:20
Batch 38 processing...
Batch 38 completed. Time taken: 00:04:35
Batch 39 processing...
Batch 39 completed. Time taken: 00:04:34
Batch 40 processing...
Batch 40 completed. Time taken: 00:04:34
Batch 41 processing...
Batch 41 completed. Time taken: 00:04:35
Batch 42 processing...
Batch 42 completed. Time taken: 00:04:41
Batch 43 processing...
Batch 43 completed. Time taken: 00:05:13
Batch 44 processing...
Batch 44 completed. Time taken: 00:04:34
Batch 45 processing...
Batch 45 completed. Time taken: 00:04:34
Batch 46 processing...
Batch 46 completed. Time taken: 00:04:35
Batch 47 processing...
Batch 47 completed. Time taken: 00:04:35
Batch 48 processing...
Batch 48 completed. Time taken: 00:05:10
Batch 49 processing...
Batch 49 completed. Time taken: 00:04:42
Batch 50 processing...
Batch 50 completed. Time taken: 00:04:35
Batch 51 processing...
Batch 51 completed. Time taken: 00:04:35
Batch 52 processing...
Batch 52 completed. Time taken: 00:04:34
Batch 53 processing...
Batch 53 completed. Time taken: 00:04:34
Batch 54 processing...
Batch 54 completed. Time taken: 00:04:35
Batch 55 processing...
Batch 55 completed. Time taken: 00:04:34
Batch 56 processing...
Batch 56 completed. Time taken: 00:04:35
Batch 57 processing...
Batch 57 completed. Time taken: 00:04:34
Batch 58 processing...
Batch 58 completed. Time taken: 00:04:34
Batch 59 processing...
Batch 59 completed. Time taken: 00:04:34
Batch 60 processing...
Batch 60 completed. Time taken: 00:04:33
Batch 61 processing...
Batch 61 completed. Time taken: 00:04:34
Batch 62 processing...
Batch 62 completed. Time taken: 00:04:34
Batch 63 processing...
Batch 63 completed. Time taken: 00:04:34
Batch 64 processing...
Batch 64 completed. Time taken: 00:04:33
Batch 65 processing...
Batch 65 completed. Time taken: 00:04:33
Batch 66 processing...
Batch 66 completed. Time taken: 00:04:34
Batch 67 processing...
Batch 67 completed. Time taken: 00:04:34
Batch 68 processing...
Batch 68 completed. Time taken: 00:04:34
Batch 69 processing...
Batch 69 completed. Time taken: 00:04:34
Batch 70 processing...
Batch 70 completed. Time taken: 00:04:33
Batch 71 processing...
Batch 71 completed. Time taken: 00:04:35
Batch 72 processing...
Batch 72 completed. Time taken: 00:04:35
Batch 73 processing...
Batch 73 completed. Time taken: 00:04:34
Batch 74 processing...
Batch 74 completed. Time taken: 00:04:33
Batch 75 processing...
Batch 75 completed. Time taken: 00:04:35
Batch 76 processing...
Batch 76 completed. Time taken: 00:04:34
Batch 77 processing...
Batch 77 completed. Time taken: 00:04:35
Batch 78 processing...
Batch 78 completed. Time taken: 00:04:35
Batch 79 processing...
Batch 79 completed. Time taken: 00:04:35
Batch 80 processing...
Batch 80 completed. Time taken: 00:04:33
Batch 81 processing...
Batch 81 completed. Time taken: 00:04:34
Batch 82 processing...
Batch 82 completed. Time taken: 00:04:34
Batch 83 processing...
Batch 83 completed. Time taken: 00:04:34
Batch 84 processing...
Batch 84 completed. Time taken: 00:04:34
Batch 85 processing...
Batch 85 completed. Time taken: 00:04:33
Batch 86 processing...
Batch 86 completed. Time taken: 00:04:34
Batch 87 processing...
Batch 87 completed. Time taken: 00:04:34
Batch 88 processing...
Batch 88 completed. Time taken: 00:04:34
Batch 89 processing...
Batch 89 completed. Time taken: 00:04:34
Batch 90 processing...
Batch 90 completed. Time taken: 00:04:33
Batch 91 processing...
Batch 91 completed. Time taken: 00:04:35
Batch 92 processing...
Batch 92 completed. Time taken: 00:04:35
Batch 93 processing...
Batch 93 completed. Time taken: 00:04:35
Batch 94 processing...
Batch 94 completed. Time taken: 00:04:33
Batch 95 processing...
Batch 95 completed. Time taken: 00:04:33
Batch 96 processing...
Batch 96 completed. Time taken: 00:04:34
Batch 97 processing...
Batch 97 completed. Time taken: 00:04:34
Batch 98 processing...
Batch 98 completed. Time taken: 00:04:34
Batch 99 processing...
Batch 99 completed. Time taken: 00:04:34
Batch 100 processing...
Batch 100 completed. Time taken: 00:04:34
Batch 101 processing...
Batch 101 completed. Time taken: 00:04:34
Batch 102 processing...
Batch 102 completed. Time taken: 00:04:34
Batch 103 processing...
Batch 103 completed. Time taken: 00:04:34
Batch 104 processing...
Batch 104 completed. Time taken: 00:04:35
Batch 105 processing...
Batch 105 completed. Time taken: 00:04:35
Batch 106 processing...
Batch 106 completed. Time taken: 00:04:34
Batch 107 processing...
Batch 107 completed. Time taken: 00:04:33
Batch 108 processing...
Batch 108 completed. Time taken: 00:04:35
Batch 109 processing...
Batch 109 completed. Time taken: 00:04:34
Batch 110 processing...
Batch 110 completed. Time taken: 00:04:33
Batch 111 processing...
Batch 111 completed. Time taken: 00:04:34
Batch 112 processing...
Batch 112 completed. Time taken: 00:04:35
Batch 113 processing...
Batch 113 completed. Time taken: 00:04:35
Batch 114 processing...
Batch 114 completed. Time taken: 00:04:35
Batch 115 processing...
Batch 115 completed. Time taken: 00:04:35
Batch 116 processing...
Batch 116 completed. Time taken: 00:04:35
Batch 117 processing...
Batch 117 completed. Time taken: 00:04:34
Batch 118 processing...
Batch 118 completed. Time taken: 00:04:35
Batch 119 processing...
Batch 119 completed. Time taken: 00:04:34
Batch 120 processing...
Batch 120 completed. Time taken: 00:04:33
Batch 121 processing...
Batch 121 completed. Time taken: 00:04:33
Batch 122 processing...
Batch 122 completed. Time taken: 00:04:35
Batch 123 processing...
Batch 123 completed. Time taken: 00:04:34
Batch 124 processing...
Batch 124 completed. Time taken: 00:04:33
Batch 125 processing...
Batch 125 completed. Time taken: 00:04:35
Batch 126 processing...
Batch 126 completed. Time taken: 00:04:34
Batch 127 processing...
Batch 127 completed. Time taken: 00:04:35
Batch 128 processing...
Batch 128 completed. Time taken: 00:04:34
Batch 129 processing...
Batch 129 completed. Time taken: 00:04:35
Batch 130 processing...
Batch 130 completed. Time taken: 00:04:33
Batch 131 processing...
Batch 131 completed. Time taken: 00:04:33
Batch 132 processing...
Batch 132 completed. Time taken: 00:04:33
Batch 133 processing...
Batch 133 completed. Time taken: 00:04:35
Batch 134 processing...
Batch 134 completed. Time taken: 00:04:34
Batch 135 processing...
Batch 135 completed. Time taken: 00:04:34
Batch 136 processing...
Batch 136 completed. Time taken: 00:04:35
Batch 137 processing...
Batch 137 completed. Time taken: 00:04:33
Batch 138 processing...
Batch 138 completed. Time taken: 00:04:33
Batch 139 processing...
Batch 139 completed. Time taken: 00:04:33
Batch 140 processing...
Batch 140 completed. Time taken: 00:04:35
Batch 141 processing...
Batch 141 completed. Time taken: 00:04:35
Batch 142 processing...
Batch 142 completed. Time taken: 00:04:35
Batch 143 processing...
Batch 143 completed. Time taken: 00:04:34
Write prediction results...
第二个脚本已完成运行
